{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Implicit_neural_representation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMg/YKlhvGR+vV3TISP45sn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TalFurman/Implict_neural_representation_of_images/blob/master/Implicit_neural_representation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yu6QaMMJ_vLg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHnbI5PtAWIU"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E82VeAZSAGHD"
      },
      "source": [
        "# Implicit neural representation exercise \n",
        "\n",
        "This is a colab to summarize the main result of the exercise [Implicit Neural repreestaiton exercise](https://github.com/TalFurman/implicit_neural_representation_project).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4eQliHX_2L-"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJi4bbLnWVIo"
      },
      "source": [
        "Clone git repo "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDOigFzhWSo2",
        "outputId": "d3a64326-db07-447d-f01d-19113ebf1f29"
      },
      "source": [
        "!git clone https://github.com/TalFurman/implicit_neural_representation_project.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'implicit_neural_representation_project'...\n",
            "remote: Enumerating objects: 266, done.\u001b[K\n",
            "remote: Counting objects: 100% (131/131), done.\u001b[K\n",
            "remote: Compressing objects: 100% (131/131), done.\u001b[K\n",
            "remote: Total 266 (delta 8), reused 0 (delta 0), pack-reused 135\u001b[K\n",
            "Receiving objects: 100% (266/266), 2.97 MiB | 7.72 MiB/s, done.\n",
            "Resolving deltas: 100% (12/12), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOMF726MXc0-"
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0,'/content/implicit_neural_representation_project')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3AKDkCrXrp5"
      },
      "source": [
        "from implicit_neural_representation_project.colab_example.MultiImageFIttingDataset import MultiImageFitting"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p70rAJjNWTGP"
      },
      "source": [
        "Main training script \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "GbJa6xIWW7js",
        "outputId": "8db579e9-f512-4cde-d827-f33693163c5e"
      },
      "source": [
        "import argparse\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "from implicit_neural_representation_project.colab_example.MultiImageFIttingDataset import MultiImageFitting\n",
        "from implicit_neural_representation_project.colab_example.Siren import Siren\n",
        "from implicit_neural_representation_project.colab_example.utils.dec_to_bin_utils import get_max_binary_enc_len\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
        "import os\n",
        "\n",
        "from implicit_neural_representation_project.colab_example.utils.misc_utils import renormalize\n",
        "\n",
        "\n",
        "def get_input_arguments():\n",
        "    \"\"\"\n",
        "    Extracts command line input arguments passed to the script.\n",
        "    :return dict: dictionary with fields 'data_path'\n",
        "    \"\"\"\n",
        "    parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
        "    parser.add_argument('--data_low_path',\n",
        "                        default= os.path.dirname(os.path.abspath(__file__)) + '/../execrsize_data/48' ,\n",
        "                        help='path to folder with images')\n",
        "    parser.add_argument('--data_high_path',\n",
        "                        default= os.path.dirname(os.path.abspath(__file__)) + '/../execrsize_data/256' ,\n",
        "                        help='path to folder with images')\n",
        "    parser.add_argument('--image_low_csv_path',\n",
        "                        default=os.path.dirname(os.path.abspath(__file__)) + '/../execrsize_data/48/image_paths.csv',\n",
        "                        help='path to folder with images')\n",
        "    parser.add_argument('--image_high_csv_path',\n",
        "                        default=os.path.dirname(os.path.abspath(__file__)) + '/../execrsize_data/256/image_paths.csv',\n",
        "                        help='path to folder with images')\n",
        "    parser.add_argument('--img_sidelength_low',  default= 48 ,\n",
        "                        help='side length of image low res ')\n",
        "    parser.add_argument('--hidden_size',  default= 48*10 ,\n",
        "                        help='side length of image')\n",
        "    parser.add_argument('--img_sidelength_high',  default= 256 ,\n",
        "                        help='side length of image low res ')\n",
        "    parser.add_argument('--apply_mask', default = False,\n",
        "                        help='mask some of the pixles')\n",
        "    parser.add_argument('--mask_percent', default = 0.1,\n",
        "                        help='how many pixels to mask from image - going from 0 -> None up to 1 -> all image')\n",
        "    parser.add_argument('--num_input_features',  default= 7,\n",
        "                        help='side length of image')\n",
        "    parser.add_argument('--norm_mean', default=0.5,\n",
        "                        help='value of mean for image normalization with pytorch transform Normalize')\n",
        "    parser.add_argument('--norm_std', default=0.5,\n",
        "                        help='value of std for image normalization with pytorch transform Normalize')\n",
        "    parser.add_argument('--as_gray_flag',  default= False,\n",
        "                        help='run experiment in grayscale')\n",
        "    parser.add_argument('--exp_name',  default= 'full_48_db_with_color_hidden_size_times_10_best',\n",
        "                        help='experiment name ')\n",
        "    parser.add_argument('--model_to_load',  default= 'best',\n",
        "                        help='model to load. Options are best or last')\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    return args\n",
        "\n",
        "\n",
        "class EvalImageInterpolation:\n",
        "    \n",
        "    def __init__(self, data_low_path:str , data_high_path:str,  sidelength_low: int,  sidelength_high: int, num_encod_features: int = None, as_gray_flag: bool = True,\n",
        "                             image_csv_path_low: str = None, image_csv_path_high: str = None, checkpoints_dir: str = None, apply_mask: bool = False,\n",
        "                             mask_percent: float = 0.0, model_to_load: str = 'best'\n",
        "                            ,norm_mean: float = 0.5, norm_std: float = 0.5, hidden_size:int = 48, num_steps:int = 10):\n",
        "\n",
        "        self.sidelength_low = sidelength_low\n",
        "        self.sidelength_high = sidelength_high\n",
        "\n",
        "        self.low_res_datastet =  MultiImageFitting(path_to_data= data_low_path, sidelength=sidelength_low, path_to_images_csv= image_csv_path_low,\n",
        "                                          as_gray_flag= as_gray_flag, apply_mask= apply_mask, mask_percent= mask_percent)\n",
        "\n",
        "        self.high_res_datastet =  MultiImageFitting(path_to_data= data_high_path, sidelength=sidelength_high, path_to_images_csv= image_csv_path_high,\n",
        "                                          as_gray_flag= as_gray_flag, apply_mask= apply_mask, mask_percent= mask_percent)\n",
        "\n",
        "        self.norm_std = norm_std\n",
        "        self.norm_mean = norm_mean\n",
        "\n",
        "        # Calculate number of encoding input features\n",
        "        if not num_encod_features:\n",
        "            self.num_encod_features = get_max_binary_enc_len(len(self.low_res_datastet))\n",
        "        else:\n",
        "            self.num_encod_features = num_encod_features\n",
        "        # Number of image channels\n",
        "        self.num_channels = 1 if as_gray_flag else 3\n",
        "\n",
        "        # Number of steps for interpolation between images\n",
        "        self.num_interp_steps = num_steps\n",
        "\n",
        "        # Model\n",
        "        self.img_siren = Siren(in_features=2 + num_encod_features, out_features=self.num_channels,\n",
        "                          hidden_features=hidden_size,\n",
        "                          hidden_layers=3, outermost_linear=True)\n",
        "\n",
        "        self.img_siren.cuda()\n",
        "        self.img_siren.eval()\n",
        "\n",
        "        # Load checkpoint\n",
        "        model_path = self.get_model_path(checkpoints_dir, model_to_load)\n",
        "        self.img_siren.load_state_dict(torch.load(model_path))\n",
        "\n",
        "        # Artifacts path\n",
        "        self.artifact_dir_path = os.path.join(checkpoints_dir, 'artifacts')\n",
        "\n",
        "    def upsample_image(self, num_examples: int = 3, random_img_flag: bool = False):\n",
        "        \"\"\"\n",
        "        Demonstrate upsampling capabilities \n",
        "        :param num_examples: number of examples to upsample\n",
        "        :param random_img_flag: bool, if False random seed is fixed and same images would be retrieved each time\n",
        "        \"\"\"\n",
        "\n",
        "        if not random_img_flag:\n",
        "            # The 256 DB has some strange black background effect non-present in training set. The following image indeces have white background\n",
        "            random_image_inds = [0,8, 62]\n",
        "        else:\n",
        "            random_image_inds = random.sample(range(len(self.low_res_datastet)), num_examples)\n",
        "\n",
        "        # Define result lists\n",
        "        gt_high_res_list = list()\n",
        "        gt_low_res_list = list()\n",
        "        upsampled_list = list()\n",
        "\n",
        "        # Upsample\n",
        "        for img_num in random_image_inds:\n",
        "\n",
        "            # Take input coords and GT images from high res dataset\n",
        "            model_input_high_res, ground_truth_high, _ = self.high_res_datastet[img_num]\n",
        "\n",
        "            gt_high_res_list.append(ground_truth_high)\n",
        "\n",
        "            # Take the GT images from the low res dataset\n",
        "            model_input_low_re, ground_truth_low, _ = self.low_res_datastet[img_num]\n",
        "\n",
        "            gt_low_res_list.append(ground_truth_low)\n",
        "\n",
        "            # Predict (up-sample) with model trained on low res\n",
        "            model_input_high_res = model_input_high_res.unsqueeze(0).cuda()\n",
        "\n",
        "\n",
        "            model_output_high_res, _ = self.img_siren(model_input_high_res)\n",
        "            upsampled_list.append(model_output_high_res)\n",
        "\n",
        "        # Visualize results\n",
        "        fig_train, axes_train = plt.subplots(3, len(upsampled_list), figsize=(18, 9))\n",
        "\n",
        "        for output_num, (model_output, ground_truth_low, ground_truth_high) in enumerate(zip(upsampled_list, gt_low_res_list, gt_high_res_list)):\n",
        "\n",
        "            # renormalize (was normalized during data preparation\n",
        "            pred_image = renormalize(model_output.cpu().view( self.sidelength_high, self.sidelength_high, self.num_channels).detach().numpy().squeeze(),\n",
        "                self.norm_std, self.norm_mean)\n",
        "            gt_high_res_image = renormalize(\n",
        "                (ground_truth_high.cpu().view(self.sidelength_high, self.sidelength_high, self.num_channels).detach().numpy().squeeze()),\n",
        "                self.norm_std, self.norm_mean)\n",
        "            gt_low_res_image = renormalize(\n",
        "                (ground_truth_low.cpu().view(self.sidelength_low, self.sidelength_low, self.num_channels).detach().numpy().squeeze()), self.norm_std, self.norm_mean)\n",
        "\n",
        "            # Save results\n",
        "            axes_train[0, output_num].imshow(pred_image)\n",
        "            axes_train[0, output_num].set_title('upsampled image')\n",
        "            axes_train[1, output_num].imshow(gt_high_res_image)\n",
        "            axes_train[1, output_num].set_title('GT high res image')\n",
        "            axes_train[2, output_num].imshow(gt_low_res_image)\n",
        "            axes_train[2, output_num].set_title('GT low res image')\n",
        "            plt.subplots_adjust(top=0.95, bottom=0.05, hspace=0.35, wspace=0)\n",
        "\n",
        "        file_name_train_images = f\"upsample_from_{self.sidelength_low}_to_{self.sidelength_high}\"\n",
        "\n",
        "        fig_train.savefig(os.path.join(self.artifact_dir_path, file_name_train_images))\n",
        "\n",
        "        plt.close('all')\n",
        "\n",
        "\n",
        "    def interpolate_between_image_pairs(self, num_chosen_pairs: int = 3, low_similarity: bool = True):\n",
        "\n",
        "        # Extract the embedding of the different images by the network (taking the last hidden layer activations\n",
        "\n",
        "        img_activations_list = list()\n",
        "        img_list = list()\n",
        "\n",
        "        for sample_ind, (model_input, ground_truth, mask) in enumerate(tqdm(self.low_res_datastet)):\n",
        "            model_input, ground_truth, mask = model_input.cuda(), ground_truth.cuda(), mask.cuda()\n",
        "            activations = self.img_siren.forward_with_activations(model_input)\n",
        "            img_list.append(ground_truth.cpu().detach().view(self.sidelength_low, self.sidelength_low, self.num_channels).numpy())\n",
        "            # The last feature map (After sine operation) is saved under 7th activation\n",
        "            last_hidden_activation = activations[\"<class 'colab_example.Siren.SineLayer'>_7\"].cpu().detach().numpy()\n",
        "            img_activations_list.append(last_hidden_activation.reshape(-1,1))\n",
        "\n",
        "        # calculate similarity between each image pair\n",
        "        img_activations_array = np.array(img_activations_list).reshape(100,-1)\n",
        "        represent_similarity = np.array(cosine_similarity(img_activations_array))\n",
        "\n",
        "        # Replace diagonal values (close to 1) with average value in matrix (so they won't reflect on highest/lowest values)\n",
        "        mat_dim = represent_similarity.shape[0]\n",
        "        mean_similarity_val = represent_similarity.mean()\n",
        "        represent_similarity[range(mat_dim), range(mat_dim)] = mean_similarity_val\n",
        "\n",
        "        for i in range(2):\n",
        "            # Hack !!! - replace max disimilarity with mean value (appears in all disimlar pairs)\n",
        "            represent_similarity[np.where(represent_similarity == represent_similarity.min())] = mean_similarity_val\n",
        "\n",
        "        # Fine num_chosen_pairs of images with least similarity\n",
        "        smallest_similarity_array = self.smallest_highest_N_indices(represent_similarity, 2*num_chosen_pairs, low_similarity)\n",
        "\n",
        "        # Skip over repeating values (due to similiarity matrix symmetry)\n",
        "        smallest_similarity_array = smallest_similarity_array[::2]\n",
        "\n",
        "\n",
        "        # Do interpolation for each pair\n",
        "\n",
        "        # Visualize image pairs\n",
        "        fig, axes = plt.subplots(2, num_chosen_pairs, figsize=(18, 6))\n",
        "\n",
        "        # For each pair\n",
        "\n",
        "        all_interped_arrays = list()\n",
        "\n",
        "        for num_img_pair, ind_vec in enumerate(smallest_similarity_array):\n",
        "            img_1 = img_list[ind_vec[0]]\n",
        "            img_2 = img_list[ind_vec[1]]\n",
        "\n",
        "            # Visualize image pairs\n",
        "            axes[0, num_img_pair].imshow(img_1)\n",
        "\n",
        "            fig_name_str = 'similar' if low_similarity == False else 'disimilar'\n",
        "\n",
        "            axes[0, num_img_pair].set_title( fig_name_str +  f' pair {num_img_pair}')\n",
        "            axes[1, num_img_pair].imshow(img_2)\n",
        "\n",
        "            hidden_img1 = img_activations_list[ind_vec[0]]\n",
        "            hidden_img2 = img_activations_list[ind_vec[1]]\n",
        "\n",
        "            interp_vec_array = self.interpolate_points(hidden_img1, hidden_img2, n_steps= self.num_interp_steps)\n",
        "\n",
        "            all_interped_arrays.append(interp_vec_array)\n",
        "        plt.subplots_adjust(top=0.95, bottom=0.05, hspace=0.35, wspace=0)\n",
        "\n",
        "        file_name_train_images = \"Image pairs chosen for interpolation with \" + fig_name_str\n",
        "        fig.savefig(os.path.join(self.artifact_dir_path, file_name_train_images))\n",
        "\n",
        "        # Show the interpolations\n",
        "\n",
        "        # Visualize image intepolation\n",
        "        fig, axes = plt.subplots(num_chosen_pairs, self.num_interp_steps, figsize=(18, 6))\n",
        "        \n",
        "        for interp_ind in range(len(all_interped_arrays)):\n",
        "            curr_interped_array = all_interped_arrays[interp_ind]\n",
        "\n",
        "            for interp_sub_ind in range(len(curr_interped_array)):\n",
        "                # Prepare interpolated activation\n",
        "                interp_activation = torch.tensor(curr_interped_array[interp_sub_ind]).squeeze()\n",
        "                interp_activation = interp_activation.view(last_hidden_activation.shape[0], last_hidden_activation.shape[1]).cuda()\n",
        "                activations[\"<class 'colab_example.Siren.SineLayer'>_7\"] = interp_activation\n",
        "\n",
        "                # Interpolate\n",
        "                new_activations = self.img_siren.forward_with_activations(activations=activations, embedding_layer_name= \"<class 'colab_example.Siren.SineLayer'>_7\")\n",
        "                new_image = new_activations[\"<class 'torch.nn.modules.linear.Linear'>_8\"].view(self.sidelength_low,self.sidelength_low,-1).cpu().detach().numpy()\n",
        "\n",
        "                # renormalize (was normalized during data preparation\n",
        "                pred_image = renormalize(new_image, self.norm_std, self.norm_mean)\n",
        "\n",
        "                # Save results\n",
        "                axes[interp_ind, interp_sub_ind].imshow(pred_image)\n",
        "                axes[interp_ind, interp_sub_ind].axis('off')\n",
        "        plt.subplots_adjust(top=0.98, bottom=0.01, hspace=0.0, wspace=0)\n",
        "        file_name_iterp_images = f\"Interpolation between pairs of {fig_name_str} images\"\n",
        "        fig.suptitle(file_name_iterp_images)\n",
        "        fig.savefig(os.path.join(self.artifact_dir_path, file_name_iterp_images))\n",
        "\n",
        "    @staticmethod\n",
        "    def transform_to_0_to_1(input_vec: np.ndarray):\n",
        "        return (input_vec - input_vec.min())/(input_vec.max()-input_vec.min())\n",
        "\n",
        "    @staticmethod\n",
        "    def smallest_highest_N_indices(input_mat: np.ndarray, num_of_min_values: int, low_similarity:bool = True) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Find #num_of_min_values minimal values indeces in an nd.array\n",
        "        :param input_mat: nd array\n",
        "        :param num_of_min_values: required number\n",
        "        :param smalest: bool if true return N smallest, else N largest values\n",
        "        :return: array with pairs of minimal values\n",
        "        \"\"\"\n",
        "        if low_similarity:\n",
        "            idx = input_mat.ravel().argsort()[:num_of_min_values]\n",
        "        else:\n",
        "            idx = input_mat.ravel().argsort()[-num_of_min_values:]\n",
        "        return np.stack(np.unravel_index(idx, input_mat.shape)).T\n",
        "\n",
        "    @staticmethod\n",
        "    def interpolate_points(p1, p2, n_steps=10):\n",
        "        # interpolate ratios between the points\n",
        "        ratios = np.linspace(0, 1, num=n_steps)\n",
        "        # linear interpolate vectors\n",
        "        vectors = list()\n",
        "        for ratio in ratios:\n",
        "            v = (1.0 - ratio) * p1 + ratio * p2\n",
        "            vectors.append(v)\n",
        "        return np.asarray(vectors)\n",
        "\n",
        "    @staticmethod\n",
        "    def get_model_path(checkpoints_dir: str, model_to_load: str = 'best'):\n",
        "        \"\"\"\n",
        "        return path to of relevant model\n",
        "        :param checkpoints_dir: path to checkpoints\n",
        "        :param model_to_load: best or last\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        if model_to_load.lower() == 'best':\n",
        "            model_path = os.path.join(checkpoints_dir, 'best_model_by_val.pth')\n",
        "        elif model_to_load.lower() == 'last':\n",
        "            model_path = os.path.join(checkpoints_dir, 'model_final.pth')\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                'Only last or best model types are valid for loading. please check the relevant argument input')\n",
        "        return model_path\n",
        "        \n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Define run arguments\n",
        "    args = get_input_arguments()\n",
        "\n",
        "    data_low_path = args.data_low_path\n",
        "    data_high_path = args.data_high_path\n",
        "\n",
        "    csv_low_path = args.image_low_csv_path\n",
        "    csv_high_path = args.image_high_csv_path\n",
        "\n",
        "    sidelength_low = args.img_sidelength_low\n",
        "    sidelength_high = args.img_sidelength_high\n",
        "\n",
        "    hidden_size = args.hidden_size\n",
        "\n",
        "    apply_mask = args.apply_mask\n",
        "    mask_percent = args.mask_percent\n",
        "    as_gray_flag = args.as_gray_flag\n",
        "    exp_name = args.exp_name\n",
        "    model_to_load = args.model_to_load\n",
        "    num_encod_features = args.num_input_features\n",
        "\n",
        "    norm_mean = args.norm_mean\n",
        "    norm_std = args.norm_std\n",
        "\n",
        "    experiment_dir = os.path.dirname(os.path.abspath(__file__)) + '/experiments/'\n",
        "\n",
        "    checkpoints_dir =  experiment_dir + exp_name\n",
        "\n",
        "    eval_image_interp = EvalImageInterpolation(data_low_path= data_low_path, data_high_path=data_high_path, sidelength_low= sidelength_low,  sidelength_high= sidelength_high, num_encod_features= num_encod_features,\n",
        "                            as_gray_flag= as_gray_flag, image_csv_path_low= csv_low_path, image_csv_path_high= csv_high_path, checkpoints_dir= checkpoints_dir, apply_mask= apply_mask,\n",
        "                            mask_percent= mask_percent, model_to_load= model_to_load, norm_mean= norm_mean, norm_std= norm_std, hidden_size= hidden_size)\n",
        "\n",
        "    # image upsampling\n",
        "    #eval_image_interp.upsample_image()\n",
        "    \n",
        "    # interpolating between images with disimilar embedding \n",
        "    eval_image_interp.interpolate_between_image_pairs(low_similarity=False)\n",
        "    \n",
        "    # interpolating between images with similar embedding \n",
        "    eval_image_interp.interpolate_between_image_pairs(low_similarity=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-2f113c0f3a9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[0;31m# Define run arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0mdata_low_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_low_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-2f113c0f3a9b>\u001b[0m in \u001b[0;36mget_input_arguments\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArgumentParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformatter_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArgumentDefaultsHelpFormatter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     parser.add_argument('--data_low_path',\n\u001b[0;32m---> 25\u001b[0;31m                         \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/../execrsize_data/48'\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                         help='path to folder with images')\n\u001b[1;32m     27\u001b[0m     parser.add_argument('--data_high_path',\n",
            "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
          ]
        }
      ]
    }
  ]
}